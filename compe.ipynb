{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Romira915/jds_compe/blob/main/compe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM5uLIQxeh7q",
        "outputId": "7b36e60e-457b-4aaf-c427-0390e318ce4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: fugashi in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Requirement already satisfied: ipadic in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.12.0+cu113)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "  !pip install mecab-python3 transformers fugashi ipadic torch_optimizer nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlRdjjoxgfeq"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import MeCab\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch import Tensor, cuda, optim\n",
        "from torch.nn import functional as F\n",
        "import torch_optimizer\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import math\n",
        "from torch.autograd.function import InplaceFunction\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.init as init\n",
        "from transformers import (AutoModel, AutoTokenizer, BertJapaneseTokenizer,\n",
        "                          BertModel, BartForSequenceClassification, BertConfig, DistilBertConfig, DistilBertTokenizer, DistilBertModel, AlbertConfig, AlbertModel, AlbertForMaskedLM, AlbertTokenizerFast)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o2aXxcHdkCE",
        "outputId": "108047a1-3959-4bec-8454-d3c9f96c615a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"popular\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q3cDMvEfO1S",
        "outputId": "ab648dfe-ad2c-48df-8145-0196692e2d9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "train_path = \"train.csv\"\n",
        "test_path = \"test.csv\"\n",
        "compe_path = \"compe.csv\"\n",
        "submission_path = \"submission.csv\"\n",
        "custom_train_path = \"training.1600000.processed.noemoticon-ja-fixed.csv\"\n",
        "\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  compe_dir = \"/content/drive/My Drive/Documents/compe/\"\n",
        "\n",
        "  train_path = compe_dir + train_path\n",
        "  test_path = compe_dir + test_path\n",
        "  compe_path = compe_dir + compe_path\n",
        "  submission_path = compe_dir + submission_path\n",
        "  custom_train_path = compe_dir + custom_train_path\n",
        "\n",
        "except ImportError:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-30wKlqKd1dU"
      },
      "outputs": [],
      "source": [
        "SEED = 223819057"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlVNSjnX1jHt",
        "outputId": "5e90e646-3f96-4e50-e906-d0c72ca92d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    24091\n",
            "1    11301\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "custom_train_df = pd.read_csv(custom_train_path)\n",
        "custom_train_df = custom_train_df[[\"text\", \"target\"]].rename(columns={\"target\": \"label\"})\n",
        "custom_train_df.loc[custom_train_df[\"label\"] == 0, \"label\"] = 1\n",
        "custom_train_df.loc[custom_train_df[\"label\"] == 4, \"label\"] = 0\n",
        "print(custom_train_df[\"label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q5yj5SMean6",
        "outputId": "af8c7038-811a-4fd4-af3c-c6db5448042f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11301\n",
            "22602\n"
          ]
        }
      ],
      "source": [
        "custom_train_df_0 = custom_train_df.query(\"label == 0\")\n",
        "custom_train_df_1 = custom_train_df.query(\"label == 1\")\n",
        "drop_size = len(custom_train_df_0) - len(custom_train_df_1)\n",
        "custom_train_df_0, _ = train_test_split(custom_train_df_0, test_size=drop_size, shuffle=True, random_state=SEED)\n",
        "print(len(custom_train_df_0))\n",
        "\n",
        "custom_train_df = pd.concat([custom_train_df_0, custom_train_df_1], axis=0)\n",
        "print(len(custom_train_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AG2fQszTgim5"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "compe_df = pd.read_csv(compe_path)\n",
        "\n",
        "train_df, valid_df = train_test_split(\n",
        "    train_df, test_size=0.2, shuffle=True, random_state=SEED)\n",
        "\n",
        "# train_df = pd.concat([train_df, test_df], axis=0)\n",
        "# train_df = pd.concat([train_df, custom_train_df], axis=0)\n",
        "\n",
        "train_text = train_df[\"text\"].values.astype('U')\n",
        "valid_text = valid_df[\"text\"].values.astype('U')\n",
        "test_text = test_df[\"text\"].values.astype('U')\n",
        "y = train_df[\"label\"].values.astype(\"int8\")\n",
        "valid_y = valid_df[\"label\"].values.astype(\"int8\")\n",
        "test_y = test_df[\"label\"].values.astype(\"int8\")\n",
        "compe_text = compe_df[\"text\"].values.astype('U')\n",
        "\n",
        "# model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "# model_name = \"daigo/bert-base-japanese-sentiment\"\n",
        "model_name = \"cl-tohoku/bert-base-japanese-whole-word-masking\"\n",
        "# model_name = \"ken11/albert-base-japanese-v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kx3l81f4ZazB"
      },
      "outputs": [],
      "source": [
        "MARK = []\n",
        "# MARK = [\"、\", \"。\", \"，\", \"．\", \"\\n\"]\n",
        "def clean_text(text):\n",
        "    replaced_text = text\n",
        "    for m in MARK:\n",
        "      replaced_text = replaced_text.replace(m, ' ')\n",
        "    # replaced_text = re.sub(r'[【】]', ' ', replaced_text)       # 【】の除去\n",
        "    # replaced_text = re.sub(r'[（）()]', ' ', replaced_text)     # （）の除去\n",
        "    # replaced_text = re.sub(r'[［］\\[\\]]', ' ', replaced_text)   # ［］の除去\n",
        "    replaced_text = re.sub(r'[@＠]\\w+', '', replaced_text)  # メンションの除去\n",
        "    replaced_text = re.sub(\n",
        "        r'https?:\\/\\/.*?[\\r\\n ]', '', replaced_text)  # URLの除去\n",
        "    replaced_text = re.sub(r'　', ' ', replaced_text)  # 全角空白の除去\n",
        "    return replaced_text\n",
        "\n",
        "def clean_url(html_text):\n",
        "    cleaned_text = re.sub(r'http\\S+', '', html_text)\n",
        "    return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMCChdK3ZVf5"
      },
      "outputs": [],
      "source": [
        "def normalize(text):\n",
        "    normalized_text = normalize_unicode(text)\n",
        "    normalized_text = normalize_number(normalized_text)\n",
        "    normalized_text = lower_text(normalized_text)\n",
        "    return normalized_text\n",
        "    \n",
        "def lower_text(text):\n",
        "    return text.lower()\n",
        "\n",
        "def normalize_unicode(text, form='NFKC'):\n",
        "    normalized_text = unicodedata.normalize(form, text)\n",
        "    return normalized_text\n",
        "\n",
        "def normalize_number(text):\n",
        "    replaced_text = re.sub(r'\\d+', '0', text)\n",
        "    return replaced_text\n",
        "    \n",
        "def lemmatize_term(term, pos=None):\n",
        "    if pos is None:\n",
        "        synsets = wordnet.synsets(term)\n",
        "        if not synsets:\n",
        "            return term\n",
        "        pos = synsets[0].pos()\n",
        "        if pos == wordnet.ADJ_SAT:\n",
        "            pos = wordnet.ADJ\n",
        "    return nltk.WordNetLemmatizer().lemmatize(term, pos=pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMj4DrD39KXF"
      },
      "outputs": [],
      "source": [
        "# 前処理\n",
        "def mark_remove(text: str):\n",
        "  text = clean_text(text)\n",
        "  # text = clean_url(text)\n",
        "  # text = normalize(text)\n",
        "  text = lower_text(text)\n",
        "  # text = normalize_unicode(text)\n",
        "  # text = \" \".join(lemmatize_term(e) for e in text.split())\n",
        "  \n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NxY0yjicBvN",
        "outputId": "33da08e2-0fc9-4708-b973-0357ecf96bf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rt : ベンチの上にカゴ並べたら入ってた。 https://t.co/ww52aqeah0\n"
          ]
        }
      ],
      "source": [
        "print(mark_remove(train_text[3260]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4oX_RStBAQ_"
      },
      "outputs": [],
      "source": [
        "v_mark_remove = np.vectorize(mark_remove)\n",
        "\n",
        "# train_text = v_mark_remove(train_text)\n",
        "# valid_text = v_mark_remove(valid_text)\n",
        "# test_text = v_mark_remove(test_text)\n",
        "# compe_text = v_mark_remove(compe_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISZnBa7kgnEo"
      },
      "outputs": [],
      "source": [
        "# Datasetの定義\n",
        "class CreateDataset(Dataset):\n",
        "    def __init__(self, X, y, tokenizer, max_len):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):  # len(Dataset)で返す値を指定\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, index):  # Dataset[index]で返す値を指定\n",
        "        text = self.X[index]\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=512,\n",
        "            pad_to_max_length=True,\n",
        "            # padding=True, \n",
        "            truncation=True,\n",
        "        )\n",
        "\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "\n",
        "        if self.max_len < sum(mask):\n",
        "          i = int(self.max_len / 2)\n",
        "          tmp = copy.copy(ids[:i])\n",
        "          tmp.extend(ids[sum(mask) - i:sum(mask)])\n",
        "          ids = tmp\n",
        "          tmp = copy.copy(mask[:i])\n",
        "          tmp.extend(mask[sum(mask) - i:sum(mask)])\n",
        "          mask = tmp\n",
        "        else:\n",
        "          ids = ids[:self.max_len]\n",
        "          mask = mask[:self.max_len]\n",
        "\n",
        "        y_tensor = torch.Tensor(\n",
        "            [1, 0]) if self.y[index] == 0 else torch.Tensor([0, 1])\n",
        "\n",
        "        return {\n",
        "            'ids': torch.LongTensor(ids),\n",
        "            'mask': torch.LongTensor(mask),\n",
        "            'labels': y_tensor\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNRZp025gsnp",
        "outputId": "7d738441-7938-41d2-95b9-7d0c3bfbc83a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ids: tensor([    2, 17232, 13817,  7124, 21804, 28589,   369,  5230,   266,  6985,\n",
            "            5,   109,     7,   103, 28796,  8228,  3318,  1577,    16,    10,\n",
            "            8, 21313, 28589, 16831,   822,   143, 20852,   465, 21573,  3374,\n",
            "         2187, 29650, 28511, 28521, 28805,   518,     3,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "labels: tensor([1., 0.])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# 最大系列長の指定\n",
        "MAX_LEN = 128\n",
        "TEST_MAX_LEN = MAX_LEN\n",
        "\n",
        "# tokenizerの取得\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(model_name)\n",
        "# tokenizer = AlbertTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "# Datasetの作成\n",
        "dataset_train = CreateDataset(\n",
        "    train_text, y, tokenizer, MAX_LEN)\n",
        "dataset_valid = CreateDataset(\n",
        "    valid_text, valid_y, tokenizer, MAX_LEN)\n",
        "dataset_test = CreateDataset(\n",
        "    test_text, test_y, tokenizer, TEST_MAX_LEN)\n",
        "dataset_compe = CreateDataset(\n",
        "    compe_text, np.zeros(len(compe_text)), tokenizer, TEST_MAX_LEN\n",
        ")\n",
        "\n",
        "for var in dataset_train[3260]:\n",
        "    print(f'{var}: {dataset_train[3260][var]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o7bECn_rjfM",
        "outputId": "12fe1a18-a1ad-4f7b-f6c2-f31b29bbadca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "最大単語数:  150\n"
          ]
        }
      ],
      "source": [
        "# 最大単語数の確認\n",
        "max_len = []\n",
        "# 1文づつ処理\n",
        "for i, sent in enumerate(compe_text):\n",
        "    # Tokenizeで分割\n",
        "    token_words = tokenizer.tokenize(sent)\n",
        "    # 文章数を取得してリストへ格納\n",
        "    max_len.append(len(token_words))\n",
        "    if len(token_words) == 136:\n",
        "      print(i)\n",
        "# 最大の値を確認\n",
        "print('最大単語数: ', max(max_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK8Oltr1cN6q"
      },
      "outputs": [],
      "source": [
        "def torch_fix_seed(seed=0):\n",
        "    # Python random\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.use_deterministic_algorithms = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIY0cZt2Ah8t"
      },
      "outputs": [],
      "source": [
        "class Mixout(InplaceFunction):\n",
        "    @staticmethod\n",
        "    def _make_noise(input):\n",
        "        return input.new().resize_as_(input)\n",
        "\n",
        "    @classmethod\n",
        "    def forward(cls, ctx, input, target=None, p=0.0, training=False, inplace=False):\n",
        "        if p < 0 or p > 1:\n",
        "            raise ValueError(\"A mix probability of mixout has to be between 0 and 1,\" \" but got {}\".format(p))\n",
        "        if target is not None and input.size() != target.size():\n",
        "            raise ValueError(\n",
        "                \"A target tensor size must match with a input tensor size {},\"\n",
        "                \" but got {}\".format(input.size(), target.size())\n",
        "            )\n",
        "        ctx.p = p\n",
        "        ctx.training = training\n",
        "\n",
        "        if ctx.p == 0 or not ctx.training:\n",
        "            return input\n",
        "\n",
        "        if target is None:\n",
        "            target = cls._make_noise(input)\n",
        "            target.fill_(0)\n",
        "        target = target.to(input.device)\n",
        "\n",
        "        if inplace:\n",
        "            ctx.mark_dirty(input)\n",
        "            output = input\n",
        "        else:\n",
        "            output = input.clone()\n",
        "\n",
        "        ctx.noise = cls._make_noise(input)\n",
        "        if len(ctx.noise.size()) == 1:\n",
        "            ctx.noise.bernoulli_(1 - ctx.p)\n",
        "        else:\n",
        "            ctx.noise[0].bernoulli_(1 - ctx.p)\n",
        "            ctx.noise = ctx.noise[0].repeat(input.size()[0], 1)\n",
        "        ctx.noise.expand_as(input)\n",
        "\n",
        "        if ctx.p == 1:\n",
        "            output = target\n",
        "        else:\n",
        "            output = ((1 - ctx.noise) * target + ctx.noise * output - ctx.p * target) / (1 - ctx.p)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        if ctx.p > 0 and ctx.training:\n",
        "            return grad_output * ctx.noise, None, None, None, None\n",
        "        else:\n",
        "            return grad_output, None, None, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R244UXceAwuK"
      },
      "outputs": [],
      "source": [
        "def mixout(input, target=None, p=0.0, training=False, inplace=False):\n",
        "    return Mixout.apply(input, target, p, training, inplace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgzqLWDEKT0-"
      },
      "outputs": [],
      "source": [
        "class MixLinear(torch.nn.Module):\n",
        "    __constants__ = [\"bias\", \"in_features\", \"out_features\"]\n",
        "    def __init__(self, in_features, out_features, bias=True, target=None, p=0.0):\n",
        "        super(MixLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter(\"bias\", None)\n",
        "        self.reset_parameters()\n",
        "        self.target = target\n",
        "        self.p = p\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.linear(input, mixout(self.weight, self.target, self.p, self.training), self.bias)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        type = \"drop\" if self.target is None else \"mix\"\n",
        "        return \"{}={}, in_features={}, out_features={}, bias={}\".format(\n",
        "            type + \"out\", self.p, self.in_features, self.out_features, self.bias is not None\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMerhkSKKUkp"
      },
      "outputs": [],
      "source": [
        "def replace_mixout(model, mixout):\n",
        "    for sup_module in model.modules():\n",
        "        for name, module in sup_module.named_children():\n",
        "            if isinstance(module, torch.nn.Dropout):\n",
        "                module.p = 0.0\n",
        "            if isinstance(module, torch.nn.Linear):\n",
        "                target_state_dict = module.state_dict()\n",
        "                bias = True if module.bias is not None else False\n",
        "                new_module = MixLinear(\n",
        "                    module.in_features, module.out_features, bias, target_state_dict[\"weight\"], mixout\n",
        "                )\n",
        "                new_module.load_state_dict(target_state_dict)\n",
        "                setattr(sup_module, name, new_module)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDzTsMLzO1H6"
      },
      "outputs": [],
      "source": [
        "def get_optimizer_grouped_parameters(model, lr, lr_decay):\n",
        "    WEIGHT_DECAY = 0.0\n",
        "    model_type = 'bert'\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters()\n",
        "                       if 'lstm' in n\n",
        "                       or 'cnn' in n\n",
        "                       or 'regressor' in n],\n",
        "            \"weight_decay\": 0.0,\n",
        "            \"lr\": 2e-5,\n",
        "        },\n",
        "    ]\n",
        "    num_layers = model.config.num_hidden_layers\n",
        "    layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n",
        "    layers.reverse()\n",
        "    lr = lr\n",
        "    for layer in layers:\n",
        "        lr *= lr_decay\n",
        "        optimizer_grouped_parameters += [\n",
        "            {\n",
        "                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": WEIGHT_DECAY,\n",
        "                \"lr\": lr,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "                \"lr\": lr,\n",
        "            },\n",
        "        ]\n",
        "    return optimizer_grouped_parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT4lQfIjgusY"
      },
      "outputs": [],
      "source": [
        "# BERT分類モデルの定義\n",
        "class BERTClass(torch.nn.Module):\n",
        "    __constants__ = [\"bias\", \"in_features\", \"out_features\"]\n",
        "    def __init__(self, pretrained, drop_rate, output_size):\n",
        "        super().__init__()\n",
        "        self.output_size = output_size\n",
        "        self.config = BertConfig.from_pretrained(pretrained)\n",
        "        # self.config = BertConfig(classifier_dropout=drop_rate)\n",
        "        self.bert = BertModel.from_pretrained(pretrained)\n",
        "        self.drop = torch.nn.Dropout(drop_rate)\n",
        "        # self.cnn1 = torch.nn.Conv1d(self.config.hidden_size, 256, kernel_size=2)\n",
        "        # self.cnn2 = torch.nn.Conv1d(256,  self.output_size , kernel_size=2,  padding=1)\n",
        "        self.fc = torch.nn.Linear(self.config.hidden_size, output_size)  # BERTの出力に合わせて768次元を指定\n",
        "\n",
        "    def forward(self, ids, mask, batch_size):\n",
        "        _, out = self.bert(ids, attention_mask=mask, return_dict=False)\n",
        "        out = self.fc(self.drop(out))\n",
        "        # out = self.fc(out)\n",
        "\n",
        "        # last_hidden_state = out['last_hidden_state'].permute(0, 2, 1)\n",
        "        # cnn_embeddings = F.relu(self.cnn1(last_hidden_state))\n",
        "        # out = self.cnn2(cnn_embeddings)\n",
        "        # out, _ = torch.max(out, 2)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ID46VTRgxgo"
      },
      "outputs": [],
      "source": [
        "def calculate_loss_and_accuracy(model, loader, device, batch_size, criterion=None):\n",
        "    \"\"\" 損失・正解率を計算\"\"\"\n",
        "    model.eval()\n",
        "    loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            # デバイスの指定\n",
        "            ids = data['ids'].to(device)\n",
        "            mask = data['mask'].to(device)\n",
        "            labels = data['labels'].to(device)\n",
        "\n",
        "            # 順伝播\n",
        "            outputs = model(ids, mask, batch_size)\n",
        "\n",
        "            # 損失計算\n",
        "            if criterion != None:\n",
        "                loss += criterion(outputs, labels).item()\n",
        "\n",
        "            # 正解率計算\n",
        "            # バッチサイズの長さの予測ラベル配列\n",
        "            pred = torch.argmax(outputs, dim=-1).cpu().numpy()\n",
        "            # バッチサイズの長さの正解ラベル配列\n",
        "            labels = torch.argmax(labels, dim=-1).cpu().numpy()\n",
        "            total += len(labels)\n",
        "            correct += (pred == labels).sum().item()\n",
        "\n",
        "    return loss / len(loader), correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k7ULY3qhOtC"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "def train_model(dataset_train, dataset_valid, batch_size, model, criterion, optimizer, num_epochs, device=None, n_splits=3):\n",
        "    \"\"\"モデルの学習を実行し、損失・正解率のログを返す\"\"\"\n",
        "    # デバイスの指定\n",
        "    model.to(device)\n",
        "\n",
        "    # dataloaderの作成\n",
        "    dataloader_train = DataLoader(\n",
        "        dataset_train, batch_size=batch_size, shuffle=True)\n",
        "    dataloader_valid = DataLoader(\n",
        "        dataset_valid, batch_size=len(dataset_valid), shuffle=False)\n",
        "    \n",
        "    # scaler = GradScaler()\n",
        "    # ITERS_TO_ACCUMULATE = 2\n",
        "\n",
        "    # 学習\n",
        "    log_train = []\n",
        "    log_valid = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # 開始時刻の記録\n",
        "        s_time = time.time()\n",
        "\n",
        "        # 訓練モードに設定\n",
        "        model.train()\n",
        "        for i, data in enumerate(dataloader_train):\n",
        "            # デバイスの指定\n",
        "            ids = data['ids'].to(device)\n",
        "            mask = data['mask'].to(device)\n",
        "            labels = data['labels'].to(device)\n",
        "\n",
        "            # 勾配をゼロで初期化\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # with autocast():\n",
        "              # 順伝播 + 誤差逆伝播 + 重み更新\n",
        "            outputs = model(ids, mask, batch_size)\n",
        "            loss = criterion(outputs, labels)\n",
        "              # loss = loss / ITERS_TO_ACCUMULATE\n",
        "            \n",
        "            loss.backward()\n",
        "            # scaler.scale(loss).backward() \n",
        "\n",
        "            del loss\n",
        "            \n",
        "            # if (i + 1) % ITERS_TO_ACCUMULATE == 0:\n",
        "            optimizer.step()\n",
        "            # scaler.step(optimizer)\n",
        "            # scaler.update() \n",
        "              # optimizer.zero_grad()\n",
        "\n",
        "        # 損失と正解率の算出\n",
        "        loss_train, acc_train = calculate_loss_and_accuracy(\n",
        "            model, dataloader_train, device, batch_size, criterion=criterion)\n",
        "        loss_valid, acc_valid = calculate_loss_and_accuracy(\n",
        "            model, dataloader_valid, device, len(dataset_valid), criterion=criterion)\n",
        "        log_train.append([loss_train, acc_train])\n",
        "        log_valid.append([loss_valid, acc_valid])\n",
        "\n",
        "        # チェックポイントの保存\n",
        "        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(\n",
        "        ), 'optimizer_state_dict': optimizer.state_dict()}, f'checkpoint{epoch + 1}.pt')\n",
        "\n",
        "        # 終了時刻の記録\n",
        "        e_time = time.time()\n",
        "\n",
        "        # ログを出力\n",
        "        print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, accuracy_train: {acc_train:.4f}, loss_valid: {loss_valid:.4f}, accuracy_valid: {acc_valid:.4f}, {(e_time - s_time):.4f}sec')\n",
        "\n",
        "    return {'train': log_train, 'valid': log_valid}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwrmnOY3gzyI",
        "outputId": "383e2c58-10b3-4f34-8514-6f7e7cb87089"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1, loss_train: 0.1528, accuracy_train: 0.9447, loss_valid: 0.2131, accuracy_valid: 0.9190, 275.3649sec\n",
            "epoch: 2, loss_train: 0.0830, accuracy_train: 0.9726, loss_valid: 0.2136, accuracy_valid: 0.9265, 274.8550sec\n",
            "epoch: 3, loss_train: 0.0756, accuracy_train: 0.9720, loss_valid: 0.2457, accuracy_valid: 0.9020, 274.8789sec\n",
            "epoch: 4, loss_train: 0.0162, accuracy_train: 0.9956, loss_valid: 0.2537, accuracy_valid: 0.9205, 274.6942sec\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "torch_fix_seed(SEED)\n",
        "# パラメータの設定\n",
        "DROP_RATE = 0.7\n",
        "OUTPUT_SIZE = 2\n",
        "BATCH_SIZE = 8\n",
        "NUM_EPOCHS = 4\n",
        "LEARNING_RATE = 2e-5\n",
        "MIX_OUT = 0.7\n",
        "\n",
        "# モデルの定義\n",
        "model = BERTClass(model_name, DROP_RATE, OUTPUT_SIZE)\n",
        "# model = replace_mixout(model, MIX_OUT)\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# オプティマイザの定義\n",
        "parameters = model.parameters()\n",
        "# optimizer = torch.optim.AdamW(params=parameters, lr=LEARNING_RATE)\n",
        "# parameters = get_optimizer_grouped_parameters(model, lr=LEARNING_RATE, lr_decay=0.95)\n",
        "optimizer = torch_optimizer.RAdam(parameters, lr=LEARNING_RATE)\n",
        "\n",
        "# デバイスの指定\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# モデルの学習\n",
        "log = train_model(dataset_train, dataset_valid, BATCH_SIZE,\n",
        "                  model, criterion, optimizer, NUM_EPOCHS, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X4U9dX1aefX3",
        "outputId": "5111614b-642c-4013-b2c3-a9eba0893369"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ログの可視化\n",
        "x_axis = [x for x in range(1, len(log['train']) + 1)]\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
        "ax[0].plot(x_axis, np.array(log['train']).T[0], label='train')\n",
        "ax[0].plot(x_axis, np.array(log['valid']).T[0], label='valid')\n",
        "ax[0].set_xlabel('epoch')\n",
        "ax[0].set_ylabel('loss')\n",
        "ax[0].legend()\n",
        "ax[1].plot(x_axis, np.array(log['train']).T[1], label='train')\n",
        "ax[1].plot(x_axis, np.array(log['valid']).T[1], label='valid')\n",
        "ax[1].set_xlabel('epoch')\n",
        "ax[1].set_ylabel('accuracy')\n",
        "ax[1].legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UCoQPF8llOe1",
        "outputId": "f01787e8-bd9f-44b1-d380-9dd09c601f6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "正解率（学習データ）：0.996\n",
            "正解率（検証データ）：0.920\n",
            "正解率（評価データ）：0.925\n"
          ]
        }
      ],
      "source": [
        "# 正解率の算出\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=1, shuffle=False)\n",
        "dataloader_valid = DataLoader(dataset_valid, batch_size=1, shuffle=False)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=1, shuffle=False)\n",
        "\n",
        "print(\n",
        "    f'正解率（学習データ）：{calculate_loss_and_accuracy(model, dataloader_train, device, 1)[1]:.3f}')\n",
        "print(\n",
        "    f'正解率（検証データ）：{calculate_loss_and_accuracy(model, dataloader_valid, device, 1)[1]:.3f}')\n",
        "print(\n",
        "    f'正解率（評価データ）：{calculate_loss_and_accuracy(model, dataloader_test, device, 1)[1]:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ELZelkUefyM"
      },
      "outputs": [],
      "source": [
        "dataloader_compe = DataLoader(dataset_compe, batch_size=1, shuffle=False)\n",
        "\n",
        "pred = []\n",
        "with torch.no_grad():\n",
        "  for data in dataloader_compe:\n",
        "    # デバイスの指定\n",
        "    ids = data['ids'].to(device)\n",
        "    mask = data['mask'].to(device)\n",
        "\n",
        "    # 順伝播\n",
        "    outputs = model(ids, mask, 1)\n",
        "\n",
        "    # 正解率計算\n",
        "    # バッチサイズの長さの予測ラベル配列\n",
        "    pred_label = torch.argmax(outputs, dim=-1).cpu().numpy()\n",
        "    pred.append(pred_label[0])\n",
        "\n",
        "  csv_data = pd.DataFrame(data=pred, columns=[\"label\"])\n",
        "  csv_data.reset_index(inplace=True)\n",
        "  csv_data = csv_data.rename(columns={'index': 'ID'})\n",
        "  # submission.csvを最大2つまで馬場宛に提出してください．良い方の結果を最終スコアとします．\n",
        "  csv_data.to_csv(submission_path, index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "compe.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}